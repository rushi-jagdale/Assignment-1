{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Machine Learning Master Pipeline System\n",
        "Covers classification and regression models with full preprocessing and evaluation\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    mean_squared_error, r2_score, mean_absolute_error\n",
        ")\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# ======================\n",
        "# Model Imports\n",
        "# ======================\n",
        "\n",
        "# Classification Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier\n",
        ")\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Regression Models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    AdaBoostRegressor\n",
        ")\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n"
      ],
      "metadata": {
        "id": "9ChmpsLM85Yp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HebEzIHYJeyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZFHOkDj2I4et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data manipulation and analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Scikit-learn components\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    mean_squared_error, r2_score, mean_absolute_error\n",
        ")\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# ======================\n",
        "# Model Imports\n",
        "# ======================\n",
        "# Purpose: Import various ML algorithms for comparison\n",
        "\n",
        "# Classification Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier\n",
        ")\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Regression Models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    AdaBoostRegressor\n",
        ")\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n"
      ],
      "metadata": {
        "id": "AKhNHYfFIUqF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose: Create reusable components for feature engineering"
      ],
      "metadata": {
        "id": "S8SIsfZUKXbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom feature engineering transformer\n",
        "    Handles:\n",
        "    - Creating new features\n",
        "    - Removing unnecessary columns\n",
        "    - Data type conversions\n",
        "    \"\"\"\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"No fitting required for this transformer\"\"\"\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Apply feature engineering transformations\n",
        "        1. Create family_size feature from existing columns\n",
        "        2. Create age groups using binning\n",
        "        3. Remove irrelevant columns\n",
        "        \"\"\"\n",
        "        X = X.copy()\n",
        "\n",
        "        # Feature 1: Family size calculation\n",
        "        if all(col in X.columns for col in ['sibsp', 'parch']):\n",
        "            X['family_size'] = X['sibsp'] + X['parch']\n",
        "\n",
        "        # Feature 2: Age categorization\n",
        "        if 'age' in X.columns:\n",
        "            bins = [0, 18, 35, 50, 100]\n",
        "            labels = ['child', 'young', 'adult', 'senior']\n",
        "            X['age_group'] = pd.cut(X['age'], bins=bins, labels=labels)\n",
        "\n",
        "        # Remove non-feature columns\n",
        "        cols_to_drop = ['name', 'ticket', 'cabin', 'boat', 'body', 'home.dest']\n",
        "        return X.drop(\n",
        "            columns=[c for c in cols_to_drop if c in X.columns],\n",
        "            errors='ignore'  # Silently ignore missing columns\n",
        "        )"
      ],
      "metadata": {
        "id": "cV7O0nrgKT2A"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Purpose: Create reusable preprocessing steps"
      ],
      "metadata": {
        "id": "nqcvsTAMKfIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_preprocessor(numeric_features, categorical_features):\n",
        "    \"\"\"\n",
        "    Create preprocessing pipeline for different feature types\n",
        "    Returns ColumnTransformer with:\n",
        "    - Numeric pipeline: Imputation + Scaling\n",
        "    - Categorical pipeline: Imputation + OneHotEncoding\n",
        "    \"\"\"\n",
        "\n",
        "    # Numeric feature processing\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n",
        "        ('scaler', StandardScaler())  # Standardize features\n",
        "    ])\n",
        "\n",
        "    # Categorical feature processing\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing categories\n",
        "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Convert to numeric\n",
        "    ])\n",
        "\n",
        "    return ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ],\n",
        "        remainder='drop'  # Discard unused columns\n",
        "    )"
      ],
      "metadata": {
        "id": "48_7mc3nKcnN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose: Define models with optimized hyperparameters"
      ],
      "metadata": {
        "id": "vlgZCj23KnL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSIFICATION_MODELS = {\n",
        "    'Logistic Regression': LogisticRegression(\n",
        "        solver='liblinear',  # For small datasets\n",
        "        random_state=42,\n",
        "        max_iter=1000  # Ensure convergence\n",
        "    ),\n",
        "    'Decision Tree': DecisionTreeClassifier(\n",
        "        random_state=42,\n",
        "        max_depth=5  # Prevent overfitting\n",
        "    ),\n",
        "    'Random Forest': RandomForestClassifier(\n",
        "        random_state=42,\n",
        "        n_estimators=200  # More trees for better performance\n",
        "    ),\n",
        "    'SVM': SVC(\n",
        "        probability=True,  # Enable predict_proba\n",
        "        random_state=42,\n",
        "        kernel='rbf'  # Non-linear kernel\n",
        "    ),\n",
        "    'K-Neighbors': KNeighborsClassifier(\n",
        "        n_neighbors=7  # Optimal for many classification tasks\n",
        "    ),\n",
        "    'XGBoost': XGBClassifier(\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'  # Proper metric for classification\n",
        "    ),\n",
        "    'LightGBM': LGBMClassifier(\n",
        "        random_state=42,\n",
        "        verbose=-1  # Suppress output\n",
        "    ),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(\n",
        "        random_state=42,\n",
        "        n_estimators=200  # More estimators for better performance\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "_Ztbcp-YKlBi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression Models Dictionary"
      ],
      "metadata": {
        "id": "u18cypFSK7Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REGRESSION_MODELS = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(\n",
        "        random_state=42,\n",
        "        alpha=0.5  # Regularization strength\n",
        "    ),\n",
        "    'Lasso Regression': Lasso(\n",
        "        random_state=42,\n",
        "        alpha=0.01  # Moderate regularization\n",
        "    ),\n",
        "    'Decision Tree': DecisionTreeRegressor(\n",
        "        random_state=42,\n",
        "        max_depth=5  # Prevent overfitting\n",
        "    ),\n",
        "    'Random Forest': RandomForestRegressor(\n",
        "        random_state=42,\n",
        "        n_estimators=200  # More trees for better performance\n",
        "    ),\n",
        "    'SVR': SVR(\n",
        "        kernel='rbf'  # Non-linear kernel\n",
        "    ),\n",
        "    'XGBoost': XGBRegressor(\n",
        "        random_state=42\n",
        "    ),\n",
        "    'LightGBM': LGBMRegressor(\n",
        "        random_state=42,\n",
        "        verbose=-1  # Suppress output\n",
        "    ),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(\n",
        "        random_state=42,\n",
        "        n_estimators=200  # More estimators for better performance\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "3CU7tbVUKrlO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose: Combine all components into a single workflow"
      ],
      "metadata": {
        "id": "BszTKgMDLKY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_pipeline(model, numeric_features, categorical_features):\n",
        "    \"\"\"\n",
        "    Create end-to-end ML pipeline:\n",
        "    1. Feature engineering\n",
        "    2. Preprocessing\n",
        "    3. Model training\n",
        "    \"\"\"\n",
        "    return Pipeline([\n",
        "        ('feature_engineer', FeatureEngineer()),  # Custom transformations\n",
        "        ('preprocessor', create_preprocessor(numeric_features, categorical_features)),  # Data preprocessing\n",
        "        ('model', model)  # ML algorithm\n",
        "    ])"
      ],
      "metadata": {
        "id": "kVUwUnISLE2E"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose: Standardized model performance assessment"
      ],
      "metadata": {
        "id": "nF_aB9sJLPbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(pipeline, X_test, y_test, problem_type):\n",
        "    \"\"\"\n",
        "    Calculate performance metrics for given problem type\n",
        "    Returns dictionary with appropriate metrics\n",
        "    \"\"\"\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    metrics = {}\n",
        "    if problem_type == 'classification':\n",
        "        metrics.update({\n",
        "            'accuracy': accuracy_score(y_test, y_pred),\n",
        "            'precision': precision_score(y_test, y_pred, average='macro'),  # Macro average for multi-class\n",
        "            'recall': recall_score(y_test, y_pred, average='macro'),\n",
        "            'f1': f1_score(y_test, y_pred, average='macro')\n",
        "        })\n",
        "    else:\n",
        "        metrics.update({\n",
        "            'mae': mean_absolute_error(y_test, y_pred),  # Mean Absolute Error\n",
        "            'mse': mean_squared_error(y_test, y_pred),  # Mean Squared Error\n",
        "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),  # Root MSE\n",
        "            'r2': r2_score(y_test, y_pred)  # R-squared\n",
        "        })\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "OeNqwhv3LNhz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose: Automated testing of all models on selected dataset"
      ],
      "metadata": {
        "id": "OY3OL01_LUku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_test_suite(dataset_name='titanic'):\n",
        "    \"\"\"\n",
        "    Main testing function that:\n",
        "    - Loads dataset\n",
        "    - Splits data\n",
        "    - Tests all models\n",
        "    - Evaluates performance\n",
        "    - Provides example predictions\n",
        "    \"\"\"\n",
        "\n",
        "    # Dataset Configuration\n",
        "    if dataset_name == 'titanic':\n",
        "        # Classification problem setup\n",
        "        data = fetch_openml('titanic', version=1, as_frame=True)\n",
        "        df = data.frame.dropna(subset=['embarked'])  # Remove incomplete cases\n",
        "        target = 'survived'\n",
        "        problem_type = 'classification'\n",
        "        numeric_features = ['age', 'fare', 'pclass', 'sibsp', 'parch']\n",
        "        categorical_features = ['sex', 'embarked']\n",
        "\n",
        "    elif dataset_name == 'diabetes':\n",
        "        # Regression problem setup\n",
        "        from sklearn.datasets import load_diabetes\n",
        "        data = load_diabetes()\n",
        "        df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "        df['target'] = data.target  # Add target column\n",
        "        target = 'target'\n",
        "        problem_type = 'regression'\n",
        "        numeric_features = data.feature_names  # All features are numeric\n",
        "        categorical_features = []\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Supported datasets: 'titanic' or 'diabetes'\")\n",
        "\n",
        "    # Data Preparation\n",
        "    X = df.drop(target, axis=1)\n",
        "    y = df[target]\n",
        "\n",
        "    if problem_type == 'classification':\n",
        "        y = y.astype(int)  # Ensure integer labels\n",
        "\n",
        "    # Train-Test Split (80-20)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=0.2,\n",
        "        random_state=42  # Reproducible splits\n",
        "    )\n",
        "\n",
        "    # Model Selection\n",
        "    models = CLASSIFICATION_MODELS if problem_type == 'classification' else REGRESSION_MODELS\n",
        "\n",
        "    # Model Testing Loop\n",
        "    results = {}\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\n{'='*30}\\nTraining {model_name}...\\n{'='*30}\")\n",
        "\n",
        "        # Pipeline Creation and Training\n",
        "        pipeline = create_model_pipeline(\n",
        "            model=model,\n",
        "            numeric_features=numeric_features,\n",
        "            categorical_features=categorical_features\n",
        "        )\n",
        "        pipeline.fit(X_train, y_train)  # Train entire pipeline\n",
        "\n",
        "        # Performance Evaluation\n",
        "        results[model_name] = evaluate_model(\n",
        "            pipeline, X_test, y_test, problem_type\n",
        "        )\n",
        "\n",
        "        # Cross-Validation (3-fold)\n",
        "        cv_metric = 'accuracy' if problem_type == 'classification' else 'r2'\n",
        "        cv_scores = cross_val_score(\n",
        "            pipeline, X, y,\n",
        "            cv=3,  # 3-fold cross-validation\n",
        "            scoring=cv_metric\n",
        "        )\n",
        "\n",
        "        # Results Reporting\n",
        "        print(f\"\\n{model_name} Results:\")\n",
        "        print(\"Test Metrics:\", {k: f\"{v:.3f}\" for k, v in results[model_name].items()})\n",
        "        print(f\"CV {cv_metric.capitalize()} Scores:\", [f\"{s:.3f}\" for s in cv_scores])\n",
        "        print(f\"Mean CV Score: {np.mean(cv_scores):.3f}\")\n",
        "\n",
        "        # Example Prediction\n",
        "        sample = X_test.iloc[[0]]  # First test case\n",
        "        print(f\"\\nSample Prediction ({model_name}):\")\n",
        "        print(\"Input Features:\")\n",
        "        print(sample)\n",
        "        print(\"Predicted:\", pipeline.predict(sample)[0])\n",
        "        print(\"Actual:\", y_test.iloc[0])\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "guv4dYTWLSwU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose: Run complete test suites"
      ],
      "metadata": {
        "id": "DbpDkTvbLe2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run classification tests on Titanic dataset\n",
        "    print(\"\\n\\n{'='*40}\\nStarting Classification Test Suite\\n{'='*40}\")\n",
        "    classification_results = run_full_test_suite('titanic')\n",
        "\n",
        "    # Run regression tests on Diabetes dataset\n",
        "    print(\"\\n\\n{'='*40}\\nStarting Regression Test Suite\\n{'='*40}\")\n",
        "    regression_results = run_full_test_suite('diabetes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owF001sULcNB",
        "outputId": "773cb015-a48e-4c66-b80c-9de3625a3bd0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "{'='*40}\n",
            "Starting Classification Test Suite\n",
            "{'='*40}\n",
            "\n",
            "==============================\n",
            "Training Logistic Regression...\n",
            "==============================\n",
            "\n",
            "Logistic Regression Results:\n",
            "Test Metrics: {'accuracy': '0.771', 'precision': '0.763', 'recall': '0.758', 'f1': '0.760'}\n",
            "CV Accuracy Scores: ['0.385', '0.794', '0.634']\n",
            "Mean CV Score: 0.604\n",
            "\n",
            "Sample Prediction (Logistic Regression):\n",
            "Input Features:\n",
            "      pclass                   name   sex  age  sibsp  parch ticket   fare  \\\n",
            "1166       3  Saade, Mr. Jean Nassr  male  NaN      0      0   2676  7.225   \n",
            "\n",
            "     cabin embarked boat  body home.dest  \n",
            "1166   NaN        C  NaN   NaN       NaN  \n",
            "Predicted: 0\n",
            "Actual: 0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training Decision Tree...\n",
            "==============================\n",
            "\n",
            "Decision Tree Results:\n",
            "Test Metrics: {'accuracy': '0.752', 'precision': '0.773', 'recall': '0.712', 'f1': '0.718'}\n",
            "CV Accuracy Scores: ['0.424', '0.622', '0.618']\n",
            "Mean CV Score: 0.555\n",
            "\n",
            "Sample Prediction (Decision Tree):\n",
            "Input Features:\n",
            "      pclass                   name   sex  age  sibsp  parch ticket   fare  \\\n",
            "1166       3  Saade, Mr. Jean Nassr  male  NaN      0      0   2676  7.225   \n",
            "\n",
            "     cabin embarked boat  body home.dest  \n",
            "1166   NaN        C  NaN   NaN       NaN  \n",
            "Predicted: 0\n",
            "Actual: 0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training Random Forest...\n",
            "==============================\n",
            "\n",
            "Random Forest Results:\n",
            "Test Metrics: {'accuracy': '0.771', 'precision': '0.763', 'recall': '0.758', 'f1': '0.760'}\n",
            "CV Accuracy Scores: ['0.429', '0.571', '0.621']\n",
            "Mean CV Score: 0.540\n",
            "\n",
            "Sample Prediction (Random Forest):\n",
            "Input Features:\n",
            "      pclass                   name   sex  age  sibsp  parch ticket   fare  \\\n",
            "1166       3  Saade, Mr. Jean Nassr  male  NaN      0      0   2676  7.225   \n",
            "\n",
            "     cabin embarked boat  body home.dest  \n",
            "1166   NaN        C  NaN   NaN       NaN  \n",
            "Predicted: 0\n",
            "Actual: 0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training SVM...\n",
            "==============================\n",
            "\n",
            "SVM Results:\n",
            "Test Metrics: {'accuracy': '0.767', 'precision': '0.759', 'recall': '0.753', 'f1': '0.756'}\n",
            "CV Accuracy Scores: ['0.381', '0.782', '0.618']\n",
            "Mean CV Score: 0.594\n",
            "\n",
            "Sample Prediction (SVM):\n",
            "Input Features:\n",
            "      pclass                   name   sex  age  sibsp  parch ticket   fare  \\\n",
            "1166       3  Saade, Mr. Jean Nassr  male  NaN      0      0   2676  7.225   \n",
            "\n",
            "     cabin embarked boat  body home.dest  \n",
            "1166   NaN        C  NaN   NaN       NaN  \n",
            "Predicted: 0\n",
            "Actual: 0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training K-Neighbors...\n",
            "==============================\n",
            "\n",
            "K-Neighbors Results:\n",
            "Test Metrics: {'accuracy': '0.763', 'precision': '0.756', 'recall': '0.748', 'f1': '0.751'}\n",
            "CV Accuracy Scores: ['0.422', '0.647', '0.630']\n",
            "Mean CV Score: 0.566\n",
            "\n",
            "Sample Prediction (K-Neighbors):\n",
            "Input Features:\n",
            "      pclass                   name   sex  age  sibsp  parch ticket   fare  \\\n",
            "1166       3  Saade, Mr. Jean Nassr  male  NaN      0      0   2676  7.225   \n",
            "\n",
            "     cabin embarked boat  body home.dest  \n",
            "1166   NaN        C  NaN   NaN       NaN  \n",
            "Predicted: 0\n",
            "Actual: 0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training XGBoost...\n",
            "==============================\n",
            "\n",
            "XGBoost Results:\n",
            "Test Metrics: {'accuracy': '0.771', 'precision': '0.763', 'recall': '0.758', 'f1': '0.760'}\n",
            "CV Accuracy Scores: ['0.422', '0.553', '0.623']\n",
            "Mean CV Score: 0.533\n",
            "\n",
            "Sample Prediction (XGBoost):\n",
            "Input Features:\n",
            "      pclass                   name   sex  age  sibsp  parch ticket   fare  \\\n",
            "1166       3  Saade, Mr. Jean Nassr  male  NaN      0      0   2676  7.225   \n",
            "\n",
            "     cabin embarked boat  body home.dest  \n",
            "1166   NaN        C  NaN   NaN       NaN  \n",
            "Predicted: 0\n",
            "Actual: 0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training LightGBM...\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LightGBM Results:\n",
            "Test Metrics: {'accuracy': '0.779', 'precision': '0.771', 'recall': '0.767', 'f1': '0.769'}\n",
            "CV Accuracy Scores: ['0.431', '0.557', '0.625']\n",
            "Mean CV Score: 0.538\n",
            "\n",
            "Sample Prediction (LightGBM):\n",
            "Input Features:\n",
            "      pclass                   name   sex  age  sibsp  parch ticket   fare  \\\n",
            "1166       3  Saade, Mr. Jean Nassr  male  NaN      0      0   2676  7.225   \n",
            "\n",
            "     cabin embarked boat  body home.dest  \n",
            "1166   NaN        C  NaN   NaN       NaN  \n",
            "Predicted: 0\n",
            "Actual: 0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training Gradient Boosting...\n",
            "==============================\n",
            "\n",
            "Gradient Boosting Results:\n",
            "Test Metrics: {'accuracy': '0.782', 'precision': '0.776', 'recall': '0.767', 'f1': '0.771'}\n",
            "CV Accuracy Scores: ['0.417', '0.571', '0.628']\n",
            "Mean CV Score: 0.539\n",
            "\n",
            "Sample Prediction (Gradient Boosting):\n",
            "Input Features:\n",
            "      pclass                   name   sex  age  sibsp  parch ticket   fare  \\\n",
            "1166       3  Saade, Mr. Jean Nassr  male  NaN      0      0   2676  7.225   \n",
            "\n",
            "     cabin embarked boat  body home.dest  \n",
            "1166   NaN        C  NaN   NaN       NaN  \n",
            "Predicted: 0\n",
            "Actual: 0\n",
            "============================================================\n",
            "\n",
            "\n",
            "{'='*40}\n",
            "Starting Regression Test Suite\n",
            "{'='*40}\n",
            "\n",
            "==============================\n",
            "Training Linear Regression...\n",
            "==============================\n",
            "\n",
            "Linear Regression Results:\n",
            "Test Metrics: {'mae': '42.794', 'mse': '2900.194', 'rmse': '53.853', 'r2': '0.453'}\n",
            "CV R2 Scores: ['0.469', '0.487', '0.510']\n",
            "Mean CV Score: 0.489\n",
            "\n",
            "Sample Prediction (Linear Regression):\n",
            "Input Features:\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "\n",
            "           s4        s5       s6  \n",
            "287  0.034309  0.032432 -0.00522  \n",
            "Predicted: 139.54755840379613\n",
            "Actual: 219.0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training Ridge Regression...\n",
            "==============================\n",
            "\n",
            "Ridge Regression Results:\n",
            "Test Metrics: {'mae': '42.804', 'mse': '2895.341', 'rmse': '53.808', 'r2': '0.454'}\n",
            "CV R2 Scores: ['0.470', '0.488', '0.508']\n",
            "Mean CV Score: 0.489\n",
            "\n",
            "Sample Prediction (Ridge Regression):\n",
            "Input Features:\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "\n",
            "           s4        s5       s6  \n",
            "287  0.034309  0.032432 -0.00522  \n",
            "Predicted: 139.71995518173478\n",
            "Actual: 219.0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training Lasso Regression...\n",
            "==============================\n",
            "\n",
            "Lasso Regression Results:\n",
            "Test Metrics: {'mae': '42.795', 'mse': '2898.368', 'rmse': '53.836', 'r2': '0.453'}\n",
            "CV R2 Scores: ['0.469', '0.487', '0.509']\n",
            "Mean CV Score: 0.489\n",
            "\n",
            "Sample Prediction (Lasso Regression):\n",
            "Input Features:\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "\n",
            "           s4        s5       s6  \n",
            "287  0.034309  0.032432 -0.00522  \n",
            "Predicted: 139.61576769899085\n",
            "Actual: 219.0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training Decision Tree...\n",
            "==============================\n",
            "\n",
            "Decision Tree Results:\n",
            "Test Metrics: {'mae': '45.937', 'mse': '3526.016', 'rmse': '59.380', 'r2': '0.334'}\n",
            "CV R2 Scores: ['0.320', '0.299', '0.186']\n",
            "Mean CV Score: 0.268\n",
            "\n",
            "Sample Prediction (Decision Tree):\n",
            "Input Features:\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "\n",
            "           s4        s5       s6  \n",
            "287  0.034309  0.032432 -0.00522  \n",
            "Predicted: 157.80769230769232\n",
            "Actual: 219.0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training Random Forest...\n",
            "==============================\n",
            "\n",
            "Random Forest Results:\n",
            "Test Metrics: {'mae': '44.415', 'mse': '2980.541', 'rmse': '54.594', 'r2': '0.437'}\n",
            "CV R2 Scores: ['0.442', '0.471', '0.405']\n",
            "Mean CV Score: 0.440\n",
            "\n",
            "Sample Prediction (Random Forest):\n",
            "Input Features:\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "\n",
            "           s4        s5       s6  \n",
            "287  0.034309  0.032432 -0.00522  \n",
            "Predicted: 142.925\n",
            "Actual: 219.0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training SVR...\n",
            "==============================\n",
            "\n",
            "SVR Results:\n",
            "Test Metrics: {'mae': '56.029', 'mse': '4332.738', 'rmse': '65.824', 'r2': '0.182'}\n",
            "CV R2 Scores: ['0.148', '0.150', '0.119']\n",
            "Mean CV Score: 0.139\n",
            "\n",
            "Sample Prediction (SVR):\n",
            "Input Features:\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "\n",
            "           s4        s5       s6  \n",
            "287  0.034309  0.032432 -0.00522  \n",
            "Predicted: 142.35294557170297\n",
            "Actual: 219.0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training XGBoost...\n",
            "==============================\n",
            "\n",
            "XGBoost Results:\n",
            "Test Metrics: {'mae': '46.389', 'mse': '3351.002', 'rmse': '57.888', 'r2': '0.368'}\n",
            "CV R2 Scores: ['0.363', '0.295', '0.257']\n",
            "Mean CV Score: 0.305\n",
            "\n",
            "Sample Prediction (XGBoost):\n",
            "Input Features:\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "\n",
            "           s4        s5       s6  \n",
            "287  0.034309  0.032432 -0.00522  \n",
            "Predicted: 183.55995\n",
            "Actual: 219.0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training LightGBM...\n",
            "==============================\n",
            "\n",
            "LightGBM Results:\n",
            "Test Metrics: {'mae': '45.660', 'mse': '3225.589', 'rmse': '56.794', 'r2': '0.391'}\n",
            "CV R2 Scores: ['0.399', '0.450', '0.385']\n",
            "Mean CV Score: 0.411\n",
            "\n",
            "Sample Prediction (LightGBM):\n",
            "Input Features:\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "\n",
            "           s4        s5       s6  \n",
            "287  0.034309  0.032432 -0.00522  \n",
            "Predicted: 156.71863629602444\n",
            "Actual: 219.0\n",
            "============================================================\n",
            "\n",
            "==============================\n",
            "Training Gradient Boosting...\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gradient Boosting Results:\n",
            "Test Metrics: {'mae': '44.734', 'mse': '2981.884', 'rmse': '54.607', 'r2': '0.437'}\n",
            "CV R2 Scores: ['0.411', '0.354', '0.342']\n",
            "Mean CV Score: 0.369\n",
            "\n",
            "Sample Prediction (Gradient Boosting):\n",
            "Input Features:\n",
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "287  0.045341 -0.044642 -0.006206 -0.015999  0.125019  0.125198  0.019187   \n",
            "\n",
            "           s4        s5       s6  \n",
            "287  0.034309  0.032432 -0.00522  \n",
            "Predicted: 164.9203458082221\n",
            "Actual: 219.0\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DfctN-KzLhgL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}